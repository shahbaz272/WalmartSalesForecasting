{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import ceil\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_log_loss_scorer(estimator,X,y):\n",
    "    weight_array = np.where(X.IsHoliday_num==1,5,1)\n",
    "    log_preds = estimator.predict(X)\n",
    "    org_preds = np.exp(log_preds)-4990\n",
    "    org_y = np.exp(y)-4990\n",
    "    error = np.mean(weight_array*np.abs(org_y-org_preds))\n",
    "    \n",
    "    return -(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss_scorer(estimator,X,y):\n",
    "    weight_array = np.where(X.IsHoliday==True,5,1)\n",
    "    preds = estimator.predict(X)\n",
    "    error = np.mean(weight_array*np.abs(y-preds))\n",
    "    \n",
    "    return -(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_error(preds,org,weights):\n",
    "    org_preds = np.exp(preds)-4990\n",
    "    error = np.mean(weights*np.abs(org-org_preds))\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputing(train,test,num_features):\n",
    "    imputer = SimpleImputer(strategy='constant',fill_value=0)\n",
    "    \n",
    "\n",
    "    imp_train = pd.DataFrame(imputer.fit_transform(train[num_features]),columns=num_features)\n",
    "    train[num_features] = imp_train\n",
    "    \n",
    "    test.reset_index(drop=True,inplace=True)\n",
    "    imp_test = pd.DataFrame(imputer.transform(test[num_features]),columns=num_features)\n",
    "    test[num_features] = imp_test\n",
    "    \n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_date_features(df):\n",
    "    \n",
    "    df['quarter'] = df['Date'].dt.quarter\n",
    "    df['month'] = df['Date'].dt.month\n",
    "    df['year'] = df['Date'].dt.year\n",
    "    #df['dayofyear'] = df['Date'].dt.dayofyear\n",
    "    df['weekofyear'] = df['Date'].dt.weekofyear\n",
    "    df['day'] = df['Date'].dt.day\n",
    "    df['days'] = (df.month-1) * 30 + df.day\n",
    "    df['tDays'] = (df.year-2010)*360 + df.days\n",
    "\n",
    "    def week_of_month(dt):\n",
    "        \"\"\" Returns the week of the month for the specified date.\n",
    "        \"\"\"\n",
    "\n",
    "        first_day = dt.replace(day=1)\n",
    "\n",
    "        dom = dt.day\n",
    "        adjusted_dom = dom + first_day.weekday()\n",
    "\n",
    "        return int(ceil(adjusted_dom/7.0))\n",
    "    \n",
    "    df['weekofmonth'] = df['Date'].apply(week_of_month)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(train,test,cat_features):\n",
    "    ohe = OneHotEncoder()\n",
    "    \n",
    "    ohe_train = ohe.fit_transform(train[cat_features]).toarray()\n",
    "    ohe_train = pd.DataFrame(ohe_train,columns=ohe.get_feature_names())\n",
    "    train.drop(cat_features,axis=1,inplace=True)\n",
    "    train.reset_index(drop=True,inplace=True)\n",
    "    train = pd.concat([train,ohe_train],axis=1)\n",
    "    \n",
    "    ohe_test = ohe.transform(test[cat_features]).toarray()\n",
    "    ohe_test = pd.DataFrame(ohe_test,columns=ohe.get_feature_names())\n",
    "    test.drop(cat_features,axis=1,inplace=True)\n",
    "    test.reset_index(drop=True,inplace=True)\n",
    "    test = pd.concat([test,ohe_test],axis=1)\n",
    "    \n",
    "    return (train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lag_features(train,test,lags):\n",
    "    \n",
    "    train['set']='Train'\n",
    "    test['set']='Test'\n",
    "    test['Weekly_Sales']=0\n",
    "    \n",
    "    one_df=pd.concat([train,test],ignore_index=True)\n",
    "    \n",
    "    lags = range(39, lags+1)\n",
    "\n",
    "    df = one_df.assign(**{'Weekly_sales(t-{})'.format(t): one_df.groupby(['Store','Dept']).Weekly_Sales.shift(t) for t in lags})\n",
    "    \n",
    "    train_set = df[df.set=='Train']\n",
    "    test_set = df[df.set=='Test']\n",
    "\n",
    "    \n",
    "    return train_set,test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_other_features(df):\n",
    "    df['IsHoliday_bin']=np.where(df.IsHoliday,1,0)\n",
    "    \n",
    "    #type_dict = {'A':1,'B':2,'C':3}\n",
    "    #df['Type_num']=df.Type.map(type_dict)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data imports and manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('walmart-recruiting-store-sales-forecasting/features.csv',parse_dates=[1])\n",
    "stores = pd.read_csv('walmart-recruiting-store-sales-forecasting/stores.csv')\n",
    "test = pd.read_csv('walmart-recruiting-store-sales-forecasting/test.csv',parse_dates=[2])\n",
    "train = pd.read_csv('walmart-recruiting-store-sales-forecasting/train.csv',parse_dates=[2])\n",
    "submission = pd.read_csv('walmart-recruiting-store-sales-forecasting/sampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.merge(left=pd.merge(left=train,right=stores,how='left'),right=features,how='left',on=['Store','Date','IsHoliday'])\n",
    "test_data = pd.merge(left = pd.merge(left=test,right=stores,how='left'),right=features,how='left',on = ['Store','Date','IsHoliday'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = create_date_features(train_data)\n",
    "test_data = create_date_features(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data = one_hot_encoding(train_data,test_data,['Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahb\\AnacondaPython\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "train_data,test_data = create_lag_features(train_data,test_data,52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = create_other_features(train_data)\n",
    "test_data = create_other_features(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = list(train_data.columns[np.isin(train_data.dtypes,['int64','float64'])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = list(train_data.columns[np.isin(train_data.dtypes,['int32','float64'])])\n",
    "train_data,test_data = imputing(train_data,test_data,num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['log_sales'] = np.log(4990+train_data.Weekly_Sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Store: 1\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 40 41 42 44 45 46 47 48 49 52 54 55 56 58 59 60 67 71 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 99 \n",
      "Store: 2\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 40 41 42 44 45 46 47 48 49 52 54 55 56 58 59 60 67 71 72 74 77 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 99 \n",
      "Store: 3\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 38 40 41 42 44 46 47 49 52 54 55 56 59 60 67 71 72 74 79 80 81 82 85 87 90 91 92 94 95 96 97 98 \n",
      "Store: 4\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 44 45 46 47 48 49 52 54 55 56 58 59 60 67 71 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 99 \n",
      "Store: 5\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 38 40 41 42 44 45 46 47 49 52 54 55 56 58 59 60 67 71 72 74 79 80 81 82 85 87 90 91 92 94 95 96 97 98 99 \n",
      "Store: 6\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 40 41 42 44 45 46 47 48 49 52 54 55 56 58 59 60 67 71 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 99 \n",
      "Store: 7\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 38 40 41 42 44 45 46 47 48 49 52 54 55 56 58 59 60 67 71 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 \n",
      "Store: 8\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 40 41 42 44 45 46 47 49 52 54 55 56 58 59 60 67 71 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 99 \n",
      "Store: 9\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 38 40 41 42 44 45 46 47 48 49 52 54 55 56 59 60 67 71 72 74 79 80 81 82 85 87 90 91 92 94 95 96 98 99 \n",
      "Store: 10\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 40 41 42 44 45 46 47 48 49 50 52 54 55 56 58 59 60 67 71 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 99 \n",
      "Store: 11\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 40 41 42 44 45 46 47 49 52 54 55 56 58 59 60 67 71 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 99 \n",
      "Store: 12\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 38 40 41 42 44 46 47 49 52 54 55 56 58 59 60 67 71 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 99 \n",
      "Store: 13\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 40 41 42 44 45 46 47 48 49 50 52 54 55 56 58 59 60 67 71 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 99 \n",
      "Store: 14\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 38 40 41 42 43 44 46 47 49 50 51 52 54 55 56 58 59 60 67 71 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 99 \n",
      "Store: 15\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 40 41 42 44 46 47 49 50 52 54 55 56 58 59 60 67 71 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 99 \n",
      "Store: 16\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 38 40 41 42 44 45 46 47 48 49 52 54 55 56 58 59 60 67 71 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 99 \n",
      "Store: 17\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 38 40 41 42 44 45 46 47 48 49 52 54 55 56 58 59 60 67 71 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 99 \n",
      "Store: 18\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 38 40 41 42 43 44 45 46 47 48 49 50 52 54 55 56 58 59 60 67 71 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 99 \n",
      "Store: 19\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 44 46 47 49 50 52 54 55 56 58 59 60 67 71 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 99 \n",
      "Store: 20\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 40 41 42 44 45 46 47 48 49 50 52 54 55 56 58 59 60 67 71 72 74 77 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 99 \n",
      "Store: 21\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 38 40 41 42 44 46 47 49 52 54 55 56 58 59 60 67 71 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 97 98 99 \n",
      "Store: 22\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 38 40 41 42 44 46 47 49 52 54 55 56 58 59 60 67 71 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 \n",
      "Store: 23\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 38 40 41 42 44 45 46 47 49 50 52 54 55 56 58 59 60 67 71 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 99 \n",
      "Store: 24\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 40 41 42 43 44 46 47 49 50 52 54 55 56 58 59 60 67 71 72 74 78 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 99 \n",
      "Store: 25\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 40 41 42 44 46 47 48 49 50 52 54 55 56 58 59 60 67 71 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 97 98 99 \n",
      "Store: 26\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 38 40 41 42 44 45 46 47 48 49 52 54 55 56 59 60 67 71 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 99 \n",
      "Store: 27\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 40 41 42 44 46 47 49 50 52 54 55 56 58 59 60 67 71 72 74 78 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 99 \n",
      "Store: 28\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 40 41 42 44 45 46 47 49 52 54 55 56 58 59 60 67 71 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 99 \n",
      "Store: 29\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 38 40 41 42 44 46 47 48 49 52 54 55 56 58 59 60 67 71 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 97 98 99 \n",
      "Store: 30\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 20 21 22 23 24 25 26 27 28 29 31 32 33 38 40 42 44 46 49 52 56 59 60 67 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 99 \n",
      "Store: 31\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 40 41 42 44 45 46 47 49 51 52 54 55 56 58 59 60 67 71 72 74 78 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 99 \n",
      "Store: 32\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 40 41 42 44 45 46 47 49 52 54 55 56 58 59 60 67 71 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 99 \n",
      "Store: 33\n",
      "1 2 3 4 5 7 8 9 10 11 12 13 14 16 17 18 20 21 22 23 25 26 31 32 38 40 41 42 44 46 49 52 55 56 59 60 67 71 72 74 79 80 81 82 83 87 90 91 92 93 94 95 96 97 98 99 \n",
      "Store: 34\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 44 45 46 47 48 49 52 54 55 56 59 60 65 67 71 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 99 \n",
      "Store: 35\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 38 40 41 42 44 46 47 49 52 54 55 56 58 59 60 67 71 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 \n",
      "Store: 36\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 20 21 22 23 24 25 26 30 31 32 33 38 40 42 44 46 49 52 55 56 59 60 67 72 74 79 80 81 82 83 87 90 91 92 93 94 95 96 97 98 99 \n",
      "Store: 37\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 20 21 22 23 24 25 26 27 28 29 31 32 33 38 40 42 44 46 49 52 55 56 59 60 67 71 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 99 \n",
      "Store: 38\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 20 21 22 23 24 25 26 27 28 29 31 32 33 34 38 40 42 44 46 49 52 55 56 59 60 67 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 99 \n",
      "Store: 39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 38 40 41 42 44 45 46 49 52 54 55 56 58 59 60 67 71 72 74 77 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 99 \n",
      "Store: 40\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 40 41 42 44 45 46 47 48 49 52 54 55 56 58 59 60 67 71 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 99 \n",
      "Store: 41\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 38 40 41 42 44 45 46 47 48 49 52 54 55 56 58 59 60 67 71 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 99 \n",
      "Store: 42\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 20 21 22 23 24 25 26 27 28 30 31 32 33 38 40 42 44 46 49 52 55 56 59 60 67 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 \n",
      "Store: 43\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 20 21 22 23 25 26 28 31 32 33 38 40 42 46 49 52 55 56 59 60 67 71 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 \n",
      "Store: 44\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 20 21 22 23 24 25 26 27 28 31 32 33 38 40 42 44 46 49 52 55 56 59 60 67 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 96 97 98 \n",
      "Store: 45\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 38 39 40 41 42 44 45 46 47 49 52 54 55 56 58 59 60 67 71 72 74 79 80 81 82 83 85 87 90 91 92 93 94 95 97 98 "
     ]
    }
   ],
   "source": [
    "validation=False\n",
    "\n",
    "features_list = ['Size','x0_A','x0_B','x0_C','year','month','day','days','IsHoliday_bin','tDays','Weekly_sales(t-47)', 'Weekly_sales(t-48)', 'Weekly_sales(t-49)',\n",
    "       'Weekly_sales(t-50)', 'Weekly_sales(t-51)', 'Weekly_sales(t-52)']\n",
    "\n",
    "train_stores = train_data.Store.unique()\n",
    "test_stores = test_data.Store.unique()\n",
    "\n",
    "detailed_data = dict()\n",
    "\n",
    "for test_store in test_stores:\n",
    "    \n",
    "    print(\"\")\n",
    "    \n",
    "    train_depts = train_data.loc[train_data.Store==test_store].Dept.unique()\n",
    "    test_depts = test_data.loc[test_data.Store==test_store].Dept.unique()\n",
    "    \n",
    "    print('Store: ' + str(test_store))\n",
    "    \n",
    "    for test_dept in test_depts:\n",
    "        \n",
    "        ##print(str(test_dept),end = \" \")        \n",
    "        less_than_10 = False\n",
    "\n",
    "        train_store_dept_data = train_data.loc[(train_data.Store==test_store) & (train_data.Dept == test_dept)]\n",
    "        test_store_dept_data = test_data[(test_data.Store==test_store) & (test_data.Dept==test_dept)]\n",
    "        \n",
    "        if (len(train_store_dept_data)<10):\n",
    "            \n",
    "            train_store_dept_data = train_data.loc[train_data.Dept == test_dept]\n",
    "            test_store_dept_data = test_data.loc[test_data.Dept == test_dept]        \n",
    "            less_than_10 = True\n",
    "        \n",
    "        X = train_store_dept_data[features_list]\n",
    "        y = train_store_dept_data.log_sales\n",
    "        weights = np.where(X.IsHoliday_bin==1,5,1)\n",
    "        \n",
    "        #model = XGBRegressor(verbosity=0,seed=28)\n",
    "        #model.fit(X,y,sample_weight=weights)\n",
    "        \n",
    "        model = RandomForestRegressor(n_estimators=500,n_jobs=-1)\n",
    "        model.fit(X,y)\n",
    "        \n",
    "        train_preds = model.predict(X)\n",
    "        test_preds = model.predict(test_store_dept_data[features_list])\n",
    "        \n",
    "        if (less_than_10):\n",
    "            \n",
    "            if(len(train_data.loc[(train_data.Store==test_store) & (train_data.Dept == test_dept)][features_list])>0):\n",
    "                train_preds = model.predict(train_data.loc[(train_data.Store==test_store) & (train_data.Dept == test_dept)][features_list])\n",
    "            else:\n",
    "                train_preds = None\n",
    "            \n",
    "            if(len(test_data.loc[(test_data.Store==test_store) & (test_data.Dept==test_dept)][features_list])>0):\n",
    "                test_preds = model.predict(test_data[(test_data.Store==test_store) & (test_data.Dept==test_dept)][features_list])\n",
    "            \n",
    "            else:\n",
    "                test_preds = None\n",
    "            \n",
    "        current_data = dict()\n",
    "        current_data['train_X'] = X\n",
    "        current_data['train_y'] = y\n",
    "        current_data['test_X'] = test_store_dept_data[features_list]\n",
    "        if validation:\n",
    "            test_y = test_dept_store_data.log_sales\n",
    "            current_data['test_y'] = test_y\n",
    "        current_data['model'] = None\n",
    "        current_data['less_data'] = less_than_10\n",
    "        current_data['train_preds'] = train_preds\n",
    "        current_data['test_preds'] = test_preds\n",
    "        \n",
    "        detailed_data[str(test_store) + '_' + str(test_dept)] = current_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_preds = [preds for dept_data in detailed_data.values() if dept_data['train_preds'] is not None \n",
    "                   for preds in dept_data['train_preds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_preds = [preds for dept_data in detailed_data.values() for preds in dept_data['test_preds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.56268203915204"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redundant_pairs_mask = (~(train_data.Store.map(str) +'-'+ train_data.Dept.map(str)).isin(test_data.Store.map(str) +'-'+ test_data.Dept.map(str)))\n",
    "train_data_red = train_data[~redundant_pairs_mask]\n",
    "log_error(all_train_preds,train_data_red.Weekly_Sales,weights=train_data_red.IsHoliday_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Weekly_Sales'] = np.exp(all_test_preds)-4990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['preds']=np.exp(all_test_preds)-4990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 "
     ]
    }
   ],
   "source": [
    "for store in t.Store.unique():\n",
    "    print(store,end=\" \")\n",
    "    for dept in t.Dept.unique():\n",
    "        subset = t.loc[(t.Store==store)&(t.Dept==dept)&(t.weekofyear.isin([48,49,50,51,52]))]\n",
    "        if (len(subset)<5):\n",
    "            continue\n",
    "\n",
    "        old_preds = np.array(subset.preds)\n",
    "        pre_mean = old_preds[1:4].mean()\n",
    "        post_mean = (old_preds[0]+old_preds[-1])/2\n",
    "        \n",
    "        if ((pre_mean/post_mean)>1.1):\n",
    "        \n",
    "            shifted = old_preds * (7-2.5)/7\n",
    "            shifted[1:] = np.array(shifted[1:5]) + np.array(old_preds[0:4]) * (2.5/7)\n",
    "            shifted[0] = old_preds[0]\n",
    "            t.loc[(t.Store==store)&(t.Dept==dept)&(t.weekofyear.isin([48,49,50,51,52])),'preds']=shifted\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Weekly_Sales'] = t.reset_index().preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('multiple_models_rf.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_preds = pd.read_csv('xgboost_post_adjustment.csv')\n",
    "mmdf_preds = pd.read_csv('multiple_models_rf.csv')\n",
    "mmxgb_preds = pd.read_csv('multiple_models_xgboost.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sub = sm_preds.Weekly_Sales*0.3333 + mmdf_preds.Weekly_Sales*0.3333 + mmxgb_preds.Weekly_Sales*0.3333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_submission = pd.DataFrame({'Id':submission.Id,'Weekly_Sales':new_sub})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_1_2012-11-02</td>\n",
       "      <td>37748.475241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_1_2012-11-09</td>\n",
       "      <td>20945.650544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_1_2012-11-16</td>\n",
       "      <td>20395.303113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_1_2012-11-23</td>\n",
       "      <td>21073.160761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_1_2012-11-30</td>\n",
       "      <td>27822.922654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Id  Weekly_Sales\n",
       "0  1_1_2012-11-02  37748.475241\n",
       "1  1_1_2012-11-09  20945.650544\n",
       "2  1_1_2012-11-16  20395.303113\n",
       "3  1_1_2012-11-23  21073.160761\n",
       "4  1_1_2012-11-30  27822.922654"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_submission.to_csv('weighted_sub.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
